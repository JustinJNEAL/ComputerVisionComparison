{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T16:35:53.435253Z",
     "start_time": "2020-11-29T16:31:43.207236Z"
    }
   },
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "import sys\n",
    "from skimage import color\n",
    "from skimage.transform import resize\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import sklearn\n",
    "import seaborn as sns\n",
    "import kerastuner\n",
    "from kerastuner.tuners import RandomSearch\n",
    "from kerastuner.engine.hyperparameters import HyperParameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T16:40:29.420462Z",
     "start_time": "2020-11-29T16:35:53.437098Z"
    }
   },
   "outputs": [],
   "source": [
    "# Preprocessing for training data\n",
    "butterfly_path = './animals/butterfly/'\n",
    "cat_path = './animals/cat/'\n",
    "chicken_path = './animals/chicken/'\n",
    "cow_path = './animals/cow/'\n",
    "dog_path = './animals/dog/'\n",
    "elephant_path = './animals/elephant/'\n",
    "horse_path = './animals/horse/'\n",
    "sheep_path = './animals/sheep/'\n",
    "spider_path = './animals/spider/'\n",
    "squirrel_path = './animals/squirrel/'\n",
    "butterfly_files = [f for f in listdir(butterfly_path) if isfile(join(butterfly_path, f))]\n",
    "cat_files = [f for f in listdir(cat_path) if isfile(join(cat_path, f))]\n",
    "chicken_files = [f for f in listdir(chicken_path) if isfile(join(chicken_path, f))]\n",
    "cow_files = [f for f in listdir(cow_path) if isfile(join(cow_path, f))]\n",
    "dog_files = [f for f in listdir(dog_path) if isfile(join(dog_path, f))]\n",
    "elephant_files = [f for f in listdir(elephant_path) if isfile(join(elephant_path, f))]\n",
    "horse_files = [f for f in listdir(horse_path) if isfile(join(horse_path, f))]\n",
    "sheep_files = [f for f in listdir(sheep_path) if isfile(join(sheep_path, f))]\n",
    "spider_files = [f for f in listdir(spider_path) if isfile(join(spider_path, f))]\n",
    "squirrel_files = [f for f in listdir(squirrel_path) if isfile(join(squirrel_path, f))]\n",
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "# Convert images to arrays and append labels to list\n",
    "for file in butterfly_files:\n",
    "    img_path = butterfly_path + file\n",
    "    y_train.append(0) # butterfly\n",
    "    img = plt.imread(img_path)\n",
    "    if (img.shape[-1] == 3):\n",
    "        grey_img = color.rgb2gray(img)\n",
    "    elif (img.shape[-1] == 4):\n",
    "        grey_img = color.rgb2gray(color.rgba2rgb(img))\n",
    "    resized_img = resize(grey_img, (100, 100))\n",
    "    X_train.append(resized_img)\n",
    "for file in cat_files:\n",
    "    img_path = cat_path + file\n",
    "    y_train.append(1) # cat\n",
    "    img = plt.imread(img_path)\n",
    "    if (img.shape[-1] == 3):\n",
    "        grey_img = color.rgb2gray(img)\n",
    "    elif (img.shape[-1] == 4):\n",
    "        grey_img = color.rgb2gray(color.rgba2rgb(img))\n",
    "    resized_img = resize(grey_img, (100, 100))\n",
    "    X_train.append(resized_img)\n",
    "for file in chicken_files:\n",
    "    img_path = chicken_path + file\n",
    "    y_train.append(2) # chicken\n",
    "    img = plt.imread(img_path)\n",
    "    if (img.shape[-1] == 3):\n",
    "        grey_img = color.rgb2gray(img)\n",
    "    elif (img.shape[-1] == 4):\n",
    "        grey_img = color.rgb2gray(color.rgba2rgb(img))\n",
    "    resized_img = resize(grey_img, (100, 100))\n",
    "    X_train.append(resized_img)\n",
    "for file in cow_files:\n",
    "    img_path = cow_path + file\n",
    "    y_train.append(3) # cow\n",
    "    img = plt.imread(img_path)\n",
    "    if (img.shape[-1] == 3):\n",
    "        grey_img = color.rgb2gray(img)\n",
    "    elif (img.shape[-1] == 4):\n",
    "        grey_img = color.rgb2gray(color.rgba2rgb(img))\n",
    "    resized_img = resize(grey_img, (100, 100))\n",
    "    X_train.append(resized_img)\n",
    "for file in dog_files:\n",
    "    img_path = dog_path + file\n",
    "    y_train.append(4) # dog\n",
    "    img = plt.imread(img_path)\n",
    "    if (img.shape[-1] == 3):\n",
    "        grey_img = color.rgb2gray(img)\n",
    "    elif (img.shape[-1] == 4):\n",
    "        grey_img = color.rgb2gray(color.rgba2rgb(img))\n",
    "    resized_img = resize(grey_img, (100, 100))\n",
    "    X_train.append(resized_img)\n",
    "for file in elephant_files:\n",
    "    img_path = elephant_path + file\n",
    "    y_train.append(5) # elephant\n",
    "    img = plt.imread(img_path)\n",
    "    if (img.shape[-1] == 3):\n",
    "        grey_img = color.rgb2gray(img)\n",
    "    elif (img.shape[-1] == 4):\n",
    "        grey_img = color.rgb2gray(color.rgba2rgb(img))\n",
    "    resized_img = resize(grey_img, (100, 100))\n",
    "    X_train.append(resized_img)\n",
    "for file in horse_files:\n",
    "    img_path = horse_path + file\n",
    "    y_train.append(6) # horse\n",
    "    img = plt.imread(img_path)\n",
    "    if (img.shape[-1] == 3):\n",
    "        grey_img = color.rgb2gray(img)\n",
    "    elif (img.shape[-1] == 4):\n",
    "        grey_img = color.rgb2gray(color.rgba2rgb(img))\n",
    "    resized_img = resize(grey_img, (100, 100))\n",
    "    X_train.append(resized_img)\n",
    "for file in sheep_files:\n",
    "    img_path = sheep_path + file\n",
    "    y_train.append(7) # sheep\n",
    "    img = plt.imread(img_path)\n",
    "    if (img.shape[-1] == 3):\n",
    "        grey_img = color.rgb2gray(img)\n",
    "    elif (img.shape[-1] == 4):\n",
    "        grey_img = color.rgb2gray(color.rgba2rgb(img))\n",
    "    resized_img = resize(grey_img, (100, 100))\n",
    "    X_train.append(resized_img)\n",
    "for file in spider_files:\n",
    "    img_path = spider_path + file\n",
    "    y_train.append(8)  # spider\n",
    "    img = plt.imread(img_path)\n",
    "    if (img.shape[-1] == 3):\n",
    "        grey_img = color.rgb2gray(img)\n",
    "    elif (img.shape[-1] == 4):\n",
    "        grey_img = color.rgb2gray(color.rgba2rgb(img))\n",
    "    resized_img = resize(grey_img, (100, 100))\n",
    "    X_train.append(resized_img)\n",
    "for file in squirrel_files:\n",
    "    img_path = squirrel_path + file\n",
    "    y_train.append(9) # squirrel\n",
    "    img = plt.imread(img_path)\n",
    "    if (img.shape[-1] == 3):\n",
    "        grey_img = color.rgb2gray(img)\n",
    "    elif (img.shape[-1] == 4):\n",
    "        grey_img = color.rgb2gray(color.rgba2rgb(img))\n",
    "    resized_img = resize(grey_img, (100, 100))\n",
    "    X_train.append(resized_img)\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T16:43:59.380082Z",
     "start_time": "2020-11-29T16:40:29.422413Z"
    }
   },
   "outputs": [],
   "source": [
    "# Preprocessing for testing data\n",
    "path = './cats/'\n",
    "files = [f for f in listdir(path) if isfile(join(path, f))]\n",
    "X_test = []\n",
    "y_test = []\n",
    "\n",
    "# Convert images to arrays and append labels to list\n",
    "for file in files:\n",
    "    img_path = path + file\n",
    "    y_test.append(1) # match label to training data\n",
    "    img = plt.imread(img_path)\n",
    "    if (img.shape[-1] == 3):\n",
    "        grey_img = color.rgb2gray(img)\n",
    "    elif (img.shape[-1] == 4):\n",
    "        grey_img = color.rgb2gray(color.rgba2rgb(img))\n",
    "    resized_img = resize(grey_img, (100, 100))\n",
    "    X_test.append(resized_img)\n",
    "    \n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T16:44:01.414252Z",
     "start_time": "2020-11-29T16:43:59.381500Z"
    }
   },
   "outputs": [],
   "source": [
    "# Shuffle training data and labels\n",
    "new_X_train, new_y_train = sklearn.utils.shuffle(X_train, y_train, random_state = 0)\n",
    "# Observe data shapes\n",
    "print(\"Train Images: \", new_X_train.shape, \"\\nTrain Labels: \", new_y_train.shape)\n",
    "print(\"\\nTest Images: \", X_test.shape, \"\\nTest Labels: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T16:44:01.796455Z",
     "start_time": "2020-11-29T16:44:01.421044Z"
    }
   },
   "outputs": [],
   "source": [
    "# Observe set of training data\n",
    "plt.figure(figsize = (8, 8))\n",
    "for i in range(9):\n",
    "    plt.subplot(3, 3, i + 1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(new_X_train[i], cmap = plt.cm.gray)\n",
    "\n",
    "#plt.savefig('train.png', bbox_inches = 'tight')    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T16:44:02.140899Z",
     "start_time": "2020-11-29T16:44:01.798212Z"
    }
   },
   "outputs": [],
   "source": [
    "# Observe set of testing data\n",
    "plt.figure(figsize = (8, 8))\n",
    "for i in range(9):\n",
    "    plt.subplot(3, 3, i + 1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(X_test[i], cmap = plt.cm.gray)\n",
    "\n",
    "#plt.savefig('test.png', bbox_inches = 'tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T16:44:02.145675Z",
     "start_time": "2020-11-29T16:44:02.143169Z"
    }
   },
   "outputs": [],
   "source": [
    "# Flatten data\n",
    "new_X_train = new_X_train.reshape(-1, 100, 100, 1)\n",
    "X_test = X_test.reshape(-1, 100, 100, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T16:44:02.154170Z",
     "start_time": "2020-11-29T16:44:02.147785Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Convert labels to categorical\n",
    "new_y_train = keras.utils.to_categorical(new_y_train, 10)\n",
    "y_test = keras.utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T16:44:02.343429Z",
     "start_time": "2020-11-29T16:44:02.176422Z"
    }
   },
   "outputs": [],
   "source": [
    "# Tune Model Parameters\n",
    "#def build_model(hp):\n",
    "    #model = keras.models.Sequential()\n",
    "    #model.add(keras.layers.Conv2D(hp.Int('units', min_value = 32, max_value = 512, step = 32), (3, 3), input_shape = new_X_train.shape[1:], activation = 'relu'))\n",
    "    #model.add(keras.layers.MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "    #for i in range(hp.Int(\"num_layers\", 1, 4)):\n",
    "        #model.add(keras.layers.Conv2D(hp.Int(f\"layer_{i}_units\", min_value = 32, max_value = 512, step = 32), (3, 3), activation = 'relu'))\n",
    "        #model.add(keras.layers.MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "\n",
    "    #model.add(keras.layers.Flatten())\n",
    "    #model.add(keras.layers.Dense(units = 10, activation = 'softmax'))\n",
    "\n",
    "    #model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "    \n",
    "    #return model\n",
    "\n",
    "# Test parameters\n",
    "#tuner = RandomSearch(build_model, objective = 'val_accuracy', max_trials = 10, executions_per_trial = 5, directory = 'results')\n",
    "#tuner.search(x = new_X_train, y = new_y_train, epochs = 20, batch_size = 15, validation_data = (X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get best parameter results\n",
    "#tuner.get_best_hyperparameters()[0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(64, (3, 3), input_shape = new_X_train.shape[1:], activation = 'relu'))\n",
    "model.add(keras.layers.MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "model.add(keras.layers.Conv2D(320, (3, 3), activation = 'relu'))\n",
    "model.add(keras.layers.MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "model.add(keras.layers.Conv2D(480, (3, 3), activation = 'relu'))\n",
    "model.add(keras.layers.MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "model.add(keras.layers.Conv2D(192, (3, 3), activation = 'relu'))\n",
    "model.add(keras.layers.MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "model.add(keras.layers.Dropout(1/3))\n",
    "\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(units = 10, activation = 'softmax'))\n",
    "\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T20:53:53.171708Z",
     "start_time": "2020-11-29T16:44:02.344901Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Train model\n",
    "model.fit(x = new_X_train, y = new_y_train, batch_size = 15, epochs = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T20:53:53.186272Z",
     "start_time": "2020-11-29T20:53:53.178030Z"
    }
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T20:57:30.013275Z",
     "start_time": "2020-11-29T20:53:53.189152Z"
    }
   },
   "outputs": [],
   "source": [
    "# Test model and show accuracy\n",
    "predicted = model.predict(X_test)\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"Testing loss: \", test_loss, \"\\nTesting Accuracy: \", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T20:58:52.228205Z",
     "start_time": "2020-11-29T20:57:30.014715Z"
    }
   },
   "outputs": [],
   "source": [
    "# Show Confusion Matrix\n",
    "labels = ['butterfly', 'cat', 'chicken', 'cow', 'dog', 'elephant', 'horse', 'sheep', 'spider', 'squirrel']\n",
    "y_test = np.argmax(y_test, axis = 1)\n",
    "predicted = np.argmax(predicted, axis = 1)\n",
    "cm = metrics.confusion_matrix(y_test, predicted)\n",
    "fig, ax = plt.subplots(figsize = (15, 10))\n",
    "ax = sns.heatmap(cm, annot = True, fmt = 'd', ax = ax, cmap = 'viridis')\n",
    "ax.set_xlabel('Predicted Label')\n",
    "ax.set_ylabel('True Label')\n",
    "ax.set_xticks([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
    "ax.set_xticklabels(labels)\n",
    "ax.set_yticks([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
    "ax.set_yticklabels(labels)\n",
    "ax.set_title('Confusion Matrix')\n",
    "plt.setp(ax.get_xticklabels(), horizontalalignment = 'left', rotation = 45)\n",
    "plt.setp(ax.get_yticklabels(), verticalalignment = 'top', rotation = -45)\n",
    "\n",
    "#plt.savefig('animals_nn_cm.png', bbox_inches = 'tight')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
